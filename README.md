# Replicating DAS

This repository replicates the results of the distributed alignment search (see the [DAS Paper](https://arxiv.org/pdf/2303.02536)) on the hierarchical equality task. Specifically, the notebook demonstrates that DAS successfully discovers causal structure in trained networks but fails on random networks.

Note: This project was part of an application to conduct mechinterp research with [Aryaman Arora](https://aryaman.io). Much of the notebook was generated by Claude Code (permitted in Aryaman's application process), as my primary goal was to replicate and examine results.

## Experimental Setup

The notebook implements a two-part experiment:

**Part 1: Random Networks** - Shows that DAS cannot construct meaningful causal structure from randomly initialized networks (~50% IIT accuracy, chance level)

**Part 2: Trained Networks** - Shows that DAS can discover causal structure in networks trained to solve the hierarchical equality task (~95%+ IIT accuracy)

## Notebook Structure

The notebook `das_replication.ipynb` contains 10 cells:

1. **Setup & Imports** - Clones the [DAS paper repository](https://github.com/atticusg/InterchangeInterventions), imports packages, and configures experimental settings (hidden_dim=64, 3 networks, 10K samples)
2. **Classifier Definition** - Defines a simple 3-layer feedforward classifier for hierarchical equality
3. **Dataset Generation** - Generates hierarchical equality dataset with pre-computed IIT labels (80/20 train/test split)
4. **Random Network Evaluation** - Initializes 3 random networks and evaluates baseline task accuracy (~50%, chance level)
5. **DAS Training (Random)** - Trains orthogonal rotation matrices using distributed interchange interventions on random networks
6. **IIT Evaluation (Random)** - Evaluates interchange intervention accuracy on random networks (~50%, showing DAS fails)
7. **Task Training** - Trains the 3 networks to actually solve the hierarchical equality task (~99%+ accuracy) with checkpointing
8. **DAS Training (Trained)** - Trains rotation matrices on the trained networks with checkpointing
9. **IIT Evaluation (Trained)** - Evaluates interchange intervention accuracy on trained networks (~96%, showing DAS succeeds)
10. **Final Comparison** - Creates publication-quality visualization comparing random vs trained networks and saves to `das-comparison.png`

## Installation

```bash
# Create virtual environment
python -m venv das-env
source das-env/bin/activate  # On Windows: das-env\Scripts\activate

# Install dependencies
pip install torch numpy pandas scikit-learn matplotlib jupyter
```

## Running the Experiment

```bash
# Activate environment
source das-env/bin/activate

# Launch Jupyter
jupyter notebook das_replication.ipynb

# Run all cells (Runtime > Run all)
```

The notebook will:

- Train networks and rotation matrices (or load from checkpoints if available)
- Re-evaluate all results on fresh test data
- Generate `das-comparison.png` showing the final results

## Key Results

**Random Networks:**

- Task Accuracy: ~50% (chance level)
- IIT Accuracy: ~50% (chance level)

**Trained Networks:**

- Task Accuracy: ~99%+ (successfully learned)
- IIT Accuracy: ~96%+ (DAS discovered structure)

This empirically confirms that DAS discovers pre-existing computational structure and does not construct spurious behaviors.

## Technical Details

- **Task**: Hierarchical equality - determine if (w=x)==(y=z) for pairs of pairs
- **Architecture**: 3-layer feedforward (Input→64→64→Output) with ReLU activations
- **DAS Method**: Learn orthogonal rotation matrices via Interchange Intervention Training (IIT)
- **Distributed Alignment**: V1 at dims 32-48, V2 at dims 48-64, base at dims 0-32
- **Convergence**: Dev accuracy ≥ 0.999 or loss delta < 1e-4
- **Checkpointing**: Trained models saved to `trained_networks.pkl` and `trained_rotations.pkl`
- **Device Support**: MPS (Apple Silicon), CUDA (NVIDIA), or CPU

## Implementation Notes

Due to dependency issues with `build_graph()` in the original repository, this implementation does not use the full DAS infrastructure. It uses `get_IIT_equality_dataset_both()` from the repository to generate data but implements rotation matrix training independently.

## References

Geiger, A., Wu, Z., Lu, C., Gonzalez, J., Icard, T., Goodman, N. D., & Potts, C. (2023). [Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations](https://arxiv.org/abs/2303.02536). arXiv preprint arXiv:2303.02536.
